# ğŸ¤– Hybrid RAG Chatbot with Multi-Query

### (í•˜ì´ë¸Œë¦¬ë“œ RAG & ë©€í‹° ì¿¼ë¦¬ ì§€ëŠ¥í˜• ì±—ë´‡)

This project is a high-performance RAG chatbot that automatically matches the user's language and provides accurate, context-aware responses. It supports both Custom OSS LLM and OpenRouter models.
ì´ í”„ë¡œì íŠ¸ëŠ” ì‚¬ìš©ìì˜ ì–¸ì–´ì— ë§ì¶° ìë™ìœ¼ë¡œ ë‹µë³€í•˜ê³  ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ê³ ì„±ëŠ¥ RAG ì±—ë´‡ì…ë‹ˆë‹¤. Custom OSS LLMê³¼ OpenRouter ëª¨ë¸ì„ ëª¨ë‘ ì§€ì›í•˜ì—¬ ìœ ì—°í•œ ì„œë²„ êµ¬ì„±ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

---

## ğŸŒŸ Key Features (ì£¼ìš” ê¸°ëŠ¥)

| Feature (ê¸°ëŠ¥)            | Description (ì„¤ëª…)                                                                                                                              |
| :------------------------ | :---------------------------------------------------------------------------------------------------------------------------------------------- |
| **Hybrid Search**         | Combines Vector and BM25 search for maximum accuracy. <br> ë²¡í„°ì™€ BM25 ê²€ìƒ‰ì„ ê²°í•©í•´ ê²€ìƒ‰ ì •í™•ë„ë¥¼ ê·¹ëŒ€í™”í–ˆìŠµë‹ˆë‹¤.                              |
| **Language Matching**     | Automatically detects the input language and responds in the same language. <br> ì‚¬ìš©ìì˜ ì§ˆë¬¸ ì–¸ì–´ë¥¼ ê°ì§€í•˜ì—¬ ì›ë¬¸ê³¼ ë™ì¼í•œ ì–¸ì–´ë¡œ ë‹µë³€í•©ë‹ˆë‹¤. |
| **Dual LLM Support**      | Supports both Custom OSS LLM and OpenRouter (Llama 3.3). <br> Custom OSS LLMê³¼ OpenRouter ëª¨ë¸ ì¤‘ ì„ íƒí•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.                  |
| **Relationship Analysis** | Visualizes entities and relationships in a table format. <br> ë¬¸ì„œ ë‚´ ì£¼ìš” ì¸ë¬¼ê³¼ ê°œì²´ ê°„ì˜ ê´€ê³„ë¥¼ ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•©ë‹ˆë‹¤.                     |
| **Resource Mgmt**         | Real-time RAM cleanup using `gc` and `del`. <br> **`gc` ë° `del`**ì„ í†µí•´ ì‚¬ìš© í›„ ë©”ëª¨ë¦¬ë¥¼ ì¦‰ì‹œ ìµœì í™”í•©ë‹ˆë‹¤.                                   |

---

## ğŸ›  Tech Stack (ê¸°ìˆ  ìŠ¤íƒ)

- **Framework:** LangChain (`community`, `core`, `openai`)
- **Frontend:** Streamlit
- **LLM:** - **Custom OSS LLM** (Default)
  - **OpenRouter Llama 3.3** (Option - Commented in code)
- **Vector DB:** ChromaDB (**In-memory mode**)
- **Embeddings:** HuggingFace (`ko-sroberta-multitask`)

---

## ğŸš€ Getting Started (ì‹œì‘í•˜ê¸°)

### 1. Requirements (ì‚¬ì „ ì¤€ë¹„)

Create a `.env` file in the root directory.
ë£¨íŠ¸ í´ë”ì— `.env` íŒŒì¼ì„ ìƒì„±í•˜ê³  í•„ìš”í•œ í‚¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.

**File: .env**

```env

# For OpenRouter (Optional)
OPENAI_API_KEY=your_openrouter_key

# For Custom OSS LLM
OSS_MODEL_NAME=your_model_name
OSS_BASE_URL=your_endpoint_url
```

### 2. Installation (ì„¤ì¹˜)

```bash
# 1. Create Virtual Environment (ê°€ìƒí™˜ê²½ ìƒì„±)
python3 -m venv .venv  # Mac/Linux
# python -m venv .venv  # Windows

# 2. Activate Virtual Environment (ê°€ìƒí™˜ê²½ í™œì„±í™”)
source .venv/bin/activate  # Mac/Linux
# .venv\Scripts\activate  # Windows

# 3. Install Dependencies (ì˜ì¡´ì„± ì„¤ì¹˜)
pip install --upgrade pip
pip install streamlit langchain langchain-openai langchain-community \
chromadb sentence-transformers pypdf docx2txt rank_bm25 python-dotenv requests
```

### 3. Run (ì‹¤í–‰)

```bash
streamlit run app.py
```

---

## ğŸ’¡ How It Works (ì‘ë™ ì›ë¦¬)

1. **Language Intelligence (ì§€ëŠ¥í˜• ë‹¤êµ­ì–´ ëŒ€ì‘):**
   - The system automatically detects the language of the user's question and strictly responds in the same language (e.g., Korean to Korean, English to English).
   - ì‚¬ìš©ìì˜ ì§ˆë¬¸ ì–¸ì–´ë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•˜ì—¬, ì§ˆë¬¸ê³¼ ë™ì¼í•œ ì–¸ì–´ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤ (í•œêµ­ì–´ ì§ˆë¬¸ì—ëŠ” í•œêµ­ì–´, ì˜ì–´ ì§ˆë¬¸ì—ëŠ” ì˜ì–´ë¡œ ëŒ€ì‘).

2. **Flexible Model Switching (ìœ ì—°í•œ ëª¨ë¸ ì „í™˜):**
   - Supports both `CustomOSSLLM` for private API endpoints and `OpenRouter` for cloud-based models (Llama 3.3). Users can easily switch between them by toggling comments in the code.
   - í”„ë¼ì´ë¹— API ì—°ë™ì„ ìœ„í•œ `CustomOSSLLM` í´ë˜ìŠ¤ì™€ í´ë¼ìš°ë“œ ê¸°ë°˜ì˜ `OpenRouter`ë¥¼ ëª¨ë‘ ì§€ì›í•˜ë©°, ì½”ë“œ ë‚´ ì£¼ì„ ì²˜ë¦¬ë¥¼ í†µí•´ í•„ìš”ì— ë”°ë¼ ëª¨ë¸ì„ ì¦‰ì‹œ êµì²´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

3. **In-Memory & Memory Optimization (ë©”ëª¨ë¦¬ ìš°ì„  ì²˜ë¦¬ ë° ìµœì í™”):**
   - To prevent SQLite "readonly database" errors, the vector store is kept in-memory.
   - Uses `gc.collect()` and `del` to explicitly clear RAM and delete temporary files whenever a document is replaced or removed.
   - SQLite íŒŒì¼ ì ê¸ˆ ì—ëŸ¬ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ë²¡í„° ì €ì¥ì†Œë¥¼ RAMì— ìœ ì§€í•˜ë©°, íŒŒì¼ì´ ë³€ê²½ë˜ê±°ë‚˜ ì‚­ì œë  ë•Œë§ˆë‹¤ `gc.collect()`ì™€ `del`ì„ ì‚¬ìš©í•´ ë©”ëª¨ë¦¬ ìì›ì„ ì¦‰ì‹œ ìµœì í™”í•©ë‹ˆë‹¤.

4. **Smart Session & UI Management (ì§€ëŠ¥í˜• ì„¸ì…˜ ë° UI ê´€ë¦¬):**
   - Implements conditional `st.rerun()` logic to prevent infinite loading loops while ensuring all UI remnants (sidebar analysis, chat history) are cleared on file changes.
   - ìƒˆë¡œìš´ íŒŒì¼ ì—…ë¡œë“œ ì‹œ ì´ì „ ì±„íŒ… ê¸°ë¡ê³¼ ì‚¬ì´ë“œë°” ì”ìƒì„ ê¹¨ë—ì´ ì§€ìš°ë˜, ì¡°ê±´ë¶€ `st.rerun()` ë¡œì§ì„ ì ìš©í•˜ì—¬ ë¬´í•œ ë¡œë”© ì—†ëŠ” ì•ˆì •ì ì¸ UI ì „í™˜ì„ ë³´ì¥í•©ë‹ˆë‹¤.

5. **Hybrid Retrieval Pipeline (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸):**
   - Combines semantic search (Vector) and keyword search (BM25) with a balanced weighting to provide the most relevant context to the LLM.
   - ì˜ë¯¸(Vector)ì™€ í‚¤ì›Œë“œ(BM25) ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì ì ˆí•œ ê°€ì¤‘ì¹˜ë¡œ ê²°í•©í•˜ì—¬, ì§ˆë¬¸ì— ëŒ€í•´ ê°€ì¥ ì •í™•í•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•´ëƒ…ë‹ˆë‹¤.
