import streamlit as st
import os
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever
from langchain.retrievers.multi_query import MultiQueryRetriever # ë©€í‹° ì¿¼ë¦¬ ì¶”ê°€
from langchain.prompts import PromptTemplate # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì¶”ê°€

# .env ë¡œë“œ
load_dotenv()

st.set_page_config(page_title="RAG Chatbot Study", page_icon="ğŸ“š")
st.title("ğŸ“š Advanced RAG ì±—ë´‡")

# 1. ë¬´ë£Œ ì„ë² ë”© ëª¨ë¸ ì„¤ì •
@st.cache_resource
def load_embeddings():
    return HuggingFaceEmbeddings(model_name="jhgan/ko-sroberta-multitask")

embeddings = load_embeddings()

# 2. íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['pdf', 'docx', 'txt'])

if uploaded_file:
    with open(uploaded_file.name, "wb") as f:
        f.write(uploaded_file.getbuffer())

    # ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• 
    if uploaded_file.name.endswith(".pdf"):
        loader = PyPDFLoader(uploaded_file.name)
    elif uploaded_file.name.endswith(".docx"):
        loader = Docx2txtLoader(uploaded_file.name)
    else:
        loader = TextLoader(uploaded_file.name)
    
    docs = loader.load()
    # ì¸ë¬¼ ì •ë³´ë¥¼ ìœ„í•´ ì²­í¬ ì‚¬ì´ì¦ˆë¥¼ ì•½ê°„ í‚¤ìš°ê³  ì˜¤ë²„ë©ì„ ëŠ˜ë ¸ìŠµë‹ˆë‹¤.
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = text_splitter.split_documents(docs)

    # 3. í•˜ì´ë¸Œë¦¬ë“œ ë¦¬íŠ¸ë¦¬ë²„ êµ¬ì„±
    vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)
    vector_retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

    bm25_retriever = BM25Retriever.from_documents(splits)
    bm25_retriever.k = 3

    ensemble_retriever = EnsembleRetriever(
        retrievers=[bm25_retriever, vector_retriever],
        weights=[0.5, 0.5]
    )

    st.success("ë¬¸ì„œ ë¶„ì„ ì™„ë£Œ! ì´ì œ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”.")

    # 4. ì±„íŒ… ë£¨í”„
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # 5. OpenRouter ëª¨ë¸ ë° í”„ë¡¬í”„íŠ¸ ì„¤ì •
        llm = ChatOpenAI(
            model_name="meta-llama/llama-3.3-70b-instruct:free",
            openai_api_key=os.getenv("OPENAI_API_KEY"),
            base_url="https://openrouter.ai/api/v1",
            temperature=0 # ì°½ì˜ì„± 0: ì§€ì¹¨ ì¤€ìˆ˜ ê·¹ëŒ€í™”
        )

        # âœ¨ ì—„ê²©í•œ í•œê¸€ ì „ìš© í”„ë¡¬í”„íŠ¸ ì •ì˜
        template = """ë‹¹ì‹ ì€ í•œêµ­ì–´ ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì•„ë˜ ì§€ì¹¨ì„ ë°˜ë“œì‹œ ì—„ìˆ˜í•˜ì—¬ [Context]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

[ì§€ì¹¨]
1. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.
2. **ì ˆëŒ€ë¡œ í•œì(æ¼¢å­—)ë¥¼ ì“°ì§€ ë§ˆì„¸ìš”.** ëª¨ë“  ë‹¨ì–´ëŠ” í•œê¸€ë¡œë§Œ í‘œê¸°í•˜ì„¸ìš”.
3. [Context]ì˜ ë‚´ìš©ì„ ìµœëŒ€í•œ í™œìš©í•˜ë˜, ì§ì ‘ì ì¸ ë‹µì´ ì—†ë‹¤ë©´ ê´€ë ¨ ë‹¨ì„œë¼ë„ ì°¾ì•„ ì„¤ëª…í•˜ì„¸ìš”.
4. ì •ë§ ê´€ë ¨ ë‚´ìš©ì´ ì—†ë‹¤ë©´ "ë¬¸ì„œì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”.

[Context]: {context}

ì§ˆë¬¸: {question}
ë‹µë³€:"""

        prompt_template = PromptTemplate(
            template=template, 
            input_variables=["context", "question"]
        )

        # 6. ë©€í‹° ì¿¼ë¦¬ ë¦¬íŠ¸ë¦¬ë²„ (ê²€ìƒ‰ ì„±ëŠ¥ ê°•í™”)
        advanced_retriever = MultiQueryRetriever.from_llm(
            retriever=ensemble_retriever, 
            llm=llm
        )

        # 7. QA ì²´ì¸ ìƒì„±
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=advanced_retriever,
            return_source_documents=True,
            chain_type_kwargs={"prompt": prompt_template} # í”„ë¡¬í”„íŠ¸ ì£¼ì…
        )
        
        with st.chat_message("assistant"):
            # ğŸŒ€ ë¡œë”© ìŠ¤í”¼ë„ˆ ì¶”ê°€ (UX ê°œì„ )
            with st.spinner("ë¬¸ì„œë¥¼ ê¼¼ê¼¼íˆ ì½ê³  ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                response = qa_chain.invoke(prompt)
                answer = response['result']
                source_documents = response.get('source_documents', [])

            st.markdown(answer)

            if source_documents:
                with st.expander("ğŸ” ì°¸ê³  ë¬¸í—Œ í™•ì¸í•˜ê¸°"):
                    for i, doc in enumerate(source_documents):
                        st.markdown(f"**[Source {i+1}]**")
                        st.write(doc.page_content)
                        if doc.metadata:
                            metadata_text = f"ğŸ“„ ì¶œì²˜: {doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')}"
                            if 'page' in doc.metadata:
                                metadata_text += f" (Page: {doc.metadata['page'] + 1})"
                            st.caption(metadata_text)
                        st.divider()

            st.session_state.messages.append({"role": "assistant", "content": answer})

    # íŒŒì¼ ì‚­ì œ
    os.remove(uploaded_file.name)